#!/bin/python3
import argparse
from configparser import ConfigParser
from datetime import datetime
from jinja2 import Template
import guestfs
import gzip
import logging
import lzma
import requests
import subprocess
import shutil
import sys
import tarfile
import tempfile
import time
import os

import cryptography
import requests
import requests_unixsocket

_log = None


class ComposeFailure(Exception):
    pass


def run_command(cmd, stdin=None, sudo=False, **kwargs):
    _log.debug('Running command: %s', cmd)
    if sudo:
        _log.info('Sudo command running')
        cmd = ['sudo'] + cmd
    _log.debug('Stdin: %s', stdin)
    p = subprocess.Popen(cmd,
                         stdout=subprocess.PIPE,
                         stderr=subprocess.PIPE,
                         **kwargs)
    stdout, stderr = p.communicate(stdin)
    rc = p.wait()

    _log.debug('Return code: %s', rc)
    _log.debug('Stdout: %s', stdout)
    _log.debug('Stderr: %s', stderr)

    if rc != 0:
        raise ComposeFailure('Command failed, status: %s, out: %s, err: %s'
                             % (rc, stdout, stderr))

    return stdout.decode('utf-8'), stderr.decode('utf-8')


def assure_symlink(workdir, source, target):
    source = os.path.join(workdir, source)
    target = os.path.join(workdir, target)
    if os.path.exists(target):
        if os.readlink(target) == source:
            return
        else:
            os.remove(target)
    os.symlink(source, target)


def parse_args():
    parser = argparse.ArgumentParser(description='Hatlocker Compose script')
    parser.add_argument('--quiet', '-q', default=False, action='store_true')
    parser.add_argument('--verbose', '-v', default=0, action='count')
    parser.add_argument('--configuration', '-c', default='compose.cfg',
                        help='Compose config file')
    parser.add_argument('--generate-keys', action='store_true',
                        help="Generate keys that don't exist yet")
    parser.add_argument('--workdir',
                        help='Working directory (temp if not specified)')
    parser.add_argument('--auto-version', default=False, action='store_true',
                        help='Automatically generate compose version')
    parser.add_argument('--debug-build', default=False, action='store_true',
                        help='Create a debug build')
    parser.add_argument('--version',
                        help='Compose version')
    # Arguments below this are for skipping compose steps for debugging
    parser.add_argument('--skip-test-image', action='store_true',
                        help='Skip creating test image')
    parser.add_argument('--skip-boot-testing', action='store_true',
                        help='Skip boot testing')
    return parser.parse_args()


def create_verity_table(workdir):
    roothashfile = os.path.join(workdir, 'roothash')
    if os.path.isfile(roothashfile):
        with open(roothashfile, 'r') as f:
            return f.read().strip()

    _log.info('Creating verity table')
    stdout, stderr = run_command(['veritysetup', 'format', '--hash=sha256',
                                  '--data-block-size=512',
                                  os.path.join(workdir, 'rootvol'),
                                  os.path.join(workdir, 'hashvol')])
    _log.info('Verity table created, parsing')

    uuid = None
    roothash = None
    for line in stdout.split('\n'):
        line = line.strip()
        if line.startswith('UUID:'):
            _log.debug('UUID line found: %s', line)
            if uuid is not None:
                raise ComposeFailure('Second UUID line found')
            uuid = line.split()[-1]
            if len(uuid) != 36:
                raise ComposeFailure('UUID length not expected')
        elif line.startswith('Root hash:'):
            _log.debug('Roothash line found: %s' % line)
            if roothash is not None:
                raise ComposeFailure('Second root hash line found')
            roothash = line.split()[-1]
            if len(roothash) != 64:
                raise ComposeFailure('Roothash length not expected')
    if uuid is None:
        raise ComposeFailure('No UUID found')
    if roothash is None:
        raise ComposeFailure('No root hash found')
    _log.info('UUID: %s', uuid)
    _log.info('Root hash: %s', roothash)

    with open(roothashfile, 'w') as f:
        f.write(roothash)

    return roothash


def setup_logging(verbosity):
    global _log

    level = None
    if verbosity == -1:
        level = logging.CRITICAL
    elif verbosity == 0:
        level = logging.ERROR
    elif verbosity == 1:
        level = logging.WARNING
    elif verbosity == 2:
        level = logging.INFO
    elif verbosity >= 3:
        level = logging.DEBUG

    logging.basicConfig(level=level)
    _log = logging.getLogger(__name__)


def clone_git_repo(git_url, target, refresh=False):
    if os.path.exists(target):
        # Exists, check that url is correct
        stdout, stderr = run_command(['git', 'remote', 'get-url', 'origin'],
                                     cwd=target)
        if stdout.strip() != git_url:
            raise ComposeFailure(
                'Git clone %s existed, but remote is incorrect' % target)
        if refresh:
            run_command(['git', 'pull'], cwd=target)
    else:
        run_command(['git', 'clone', git_url, target])
    stdout, stderr = run_command(['git', 'rev-parse', 'HEAD'],
                                 cwd=target)
    return stdout.strip()


def wait_for_compose(config, composeid):
    res = call_osbuild_api(
        config,
        f"/compose/info/{composeid}"
    )
    status = res['queue_status']

    _log.info('Waiting for compose to finish...')

    while status in ['WAITING', 'RUNNING']:
        _log.debug(f'Status: {status}')
        time.sleep(10)
        res = call_osbuild_api(
            config,
            f"/compose/info/{composeid}"
        )
        status = res['queue_status']

    _log.info(f'Final status: {status}')

    if status != 'FINISHED':
        raise ComposeFailure('Compose failed with status %s' % status)

    return composeid


def get_blueprint(workdir, config, version):
    tmpl = None
    with open(os.path.join(workdir, 'definitions',
                           config['definitions']['blueprint'])) as f:
        tmpl = Template(f.read())
    env = {}
    env['distro'] = config['definitions']['distro']
    env['version'] = version
    return tmpl.render(**env)


def create_cmdline(workdir, debug, config, rootuuid, roothash):
    cmds = ['root=/dev/mapper/usr',
            'rd.lvm.conf=0',
            'rd.lvm.vg=hldatavg',
            'rd.luks.uuid=luks-ca9ea0ec-7514-11e7-a171-e4a4714acfe5',
            'rd.auto=1',
            'ro',
            'readonlyroot',
            'LANG=en_US.UTF-8',
            'console=tty0 console=ttyS0,115200n8',
            'verity.usr=UUID=%s' % rootuuid,
            'verity.usrhash=%s' % roothash]
    if debug:
        cmds.extend(['text',
                     'debug',
                     'rd.shell',
                     'rd.retry=10',
                     'rd.timeout=30'])
    else:
        cmds.extend(['rhgb',
                     'quiet',
                     'rd.emergency=reboot'])
    cmdline = ' '.join(cmds)
    _log.info('Command line: %s', cmdline)
    with open(os.path.join(workdir, 'cmdline'), 'w') as f:
        f.write(cmdline)


def create_qemu_cmd(workdir, config):
    machinetype = 'q35,smm=on'
    if config['testing'].getboolean('use_kvm'):
        machinetype += ',accel=kvm'
    cmd = [
        config['testing']['qemu_binary'],
        '-machine', machinetype,
        '-no-user-config',
        '-nodefaults',
        '-m', '2048',
        '-smp', '2,sockets=2,cores=1,threads=1',
        '-chardev', 'pty,id=charserial1',
        '-device', 'isa-serial,chardev=charserial1,id=serial1',
        #'-global', 'driver=cfi.pflash01,property=secure,value=on',
        '-drive',
        'file=%s,if=pflash,format=raw,unit=0,readonly=on' % (
            config['testing']['ovmf_code']),
        '-drive',
        'file=%s,if=pflash,format=raw,unit=1,readonly=on' % (
            config['testing']['ovmf_vars']),
        '-serial', 'stdio',
        '-drive',
        'file=%s,if=none,format=raw,id=drive-sata0-0-0' % (
            os.path.join(workdir, 'test.img')),
        '-device',
        'ide-hd,bus=ide.0,drive=drive-sata0-0-0,id=sata0-0-0',
        '-display', 'none']
    return cmd


def combine_files(dst, *srcs, **kwargs):
    if os.path.isfile(dst):
        return

    openfunc = open
    if kwargs.get('lzma', False):
        openfunc = lzma.open
    elif kwargs.get('gzip', False):
        openfunc = gzip.open

    with openfunc(dst + '.tmp', 'wb') as dstf:
        for src in srcs:
            with open(src, 'rb') as srcf:
                shutil.copyfileobj(srcf, dstf)

    os.rename(dst + '.tmp', dst)


def create_efi_binary(workdir, config):
    run_command(
        ['objcopy',
         '--add-section', '.osrel=%s' % os.path.join(workdir,
                                                     'definitions',
                                                     'osrelease'),
         '--change-section-vma', '.osrel=0x20000',
         '--add-section', '.cmdline=%s' % os.path.join(workdir, 'cmdline'),
         '--change-section-vma', '.cmdline=0x30000',
         '--add-section', '.linux=%s' % os.path.join(workdir, 'vmlinuz'),
         '--change-section-vma', '.linux=0x2000000',
         '--add-section', '.initrd=%s' % os.path.join(workdir, 'initramfs'),
         '--change-section-vma', '.initrd=0x3000000',
         config['efi']['stub_path'], os.path.join(workdir, 'efiapp')])


def extract_image(workdir, bodyfile):
    systemmappath = os.path.join(workdir, 'System.map')
    vmlinuzpath = os.path.join(workdir, 'vmlinuz')
    initrdpath = os.path.join(workdir, 'initramfs')
    rootvolpath = os.path.join(workdir, 'rootvol')
    if os.path.isfile(systemmappath) and \
            os.path.isfile(vmlinuzpath) and \
            os.path.isfile(initrdpath) and \
            os.path.isfile(rootvolpath):
        return

    os.environ['LIBGUESTFS_BACKEND'] = 'direct'
    g = guestfs.GuestFS(python_return_dict=True)
    g.add_drive_opts(bodyfile, readonly=1)

    _log.info('Launching GuestFS')
    g.launch()
    _log.info('GuestFS ready')
    oss = g.inspect_os()
    _log.debug('OSs: %s', oss)
    if len(oss) != 1:
        raise ComposeFailure('Not exactly one OS found')
    osroot = oss[0]
    fss = g.list_filesystems()
    _log.debug(f"Filesystems: {fss}")
    if len(fss) != 3:
        raise ComposeFailure("Not exactly three partitions ofund")
    if fss['/dev/sda1'] != 'vfat':
        raise ComposeFailure("First partition isn't vfat")
    # The image as osbuild builds it has:
    # sda1: /boot/efi
    # sda2: /boot
    # sda3: /

    bootvol = '/dev/sda2'
    rootvol = '/dev/sda3'

    _log.info('Mounting filesystem')
    g.mount_ro(rootvol, '/')
    g.mount_ro(bootvol, '/boot')
    _log.info('Filesystems mounted')

    _log.info('Downloading kernel data')
    systemmap = None
    vmlinuz = None
    initramfs = None
    for fname in g.ls('/boot'):
        if fname.startswith('System.map'):
            _log.debug('System.map found: %s', fname)
            if systemmap is not None:
                raise ComposeFailure('More than one system.map found')
            systemmap = fname
        elif fname.startswith('vmlinuz-') and not 'rescue' in fname:
            _log.debug('Vmlinuz found: %s', fname)
            if vmlinuz is not None:
                raise ComposeFailure('More than one vmlinuz found')
            vmlinuz = fname
        elif fname.startswith('initramfs-') and not 'rescue' in fname:
            _log.debug('Initramfs found: %s', fname)
            if initramfs is not None:
                raise ComposeFailure('More than one initramfs found')
            initramfs = fname
    if not systemmap:
        raise ComposeFailure('No system.map found')
    if not vmlinuz:
        raise ComposeFailure('No vmlinuz found')
    if not initramfs:
        raise ComposeFailure('No initramfs found')
    _log.debug('Downloading vmlinuz: %s, initramfs: %s', vmlinuz, initramfs)
    g.download('/boot/%s' % systemmap, systemmappath + '.tmp')
    g.download('/boot/%s' % vmlinuz, vmlinuzpath + '.tmp')
    g.download('/boot/%s' % initramfs, initrdpath + '.tmp')
    _log.info('Kernel data downloaded')

    _log.info('Downloading root volume')
    g.download(rootvol, rootvolpath + '.tmp')
    _log.info('Root volume downloaded')

    _log.info('Clearing up GuestFS')
    g.umount_all()
    _log.info('GuestFS cleared')

    os.rename(systemmappath + '.tmp', systemmappath)
    os.rename(vmlinuzpath + '.tmp', vmlinuzpath)
    os.rename(initrdpath + '.tmp', initrdpath)
    os.rename(rootvolpath + '.tmp', rootvolpath)


def get_blkfile_uuid(workdir, filename):
    stdout, stderr = run_command(['blkid',
                                  os.path.join(workdir, filename)])
    stdout = stdout.strip().split()
    blkuuid = None
    for part in stdout:
        if part.startswith('UUID="'):
            _log.debug('UUID part found: %s', part)
            if blkuuid is not None:
                raise ComposeFailure('Multiple UUID parts found')
            # String example: UUID="44772f90-22e2-424a-ae5e-3e2064ace80d"
            blkuuid = part[6:-1]
            if len(blkuuid) != 36:
                raise ComposeFailure('UUID length unexpected')
    _log.info('%s blkuuid: %s', filename, blkuuid)
    return blkuuid


curphase = None
def phase_msg(phase=None):
    global curphase
    if phase:
        curphase = phase
        print('START: %s' % phase)
    else:
        print('DONE: %s' % curphase)


def call_osbuild_api(config, url, *, json=None, body=None, body_type=None, stream=False):
    socket = config['compose']['composer_api'].replace("/", "%2F")

    url = f"http+unix://{socket}/api/v1{url}"
    if json is not None:
        _log.debug(f"Calling composer CLI at {url}, with json body {json}")
    elif body is not None:
        if body_type is None:
            raise ValueError("Body_type can't be None with non-None body")
        _log.debug(f"Calling composer CLI at {url}, with body {body} (type {body_type})")
    else:
        _log.debug(f"Calling composer CLI GET at {url}")

    session = requests_unixsocket.Session()
    if json is not None:
        r = session.post(
            url,
            json=json,
            headers={
                'Content-Type': 'application/json'
            })
    elif body is not None:
        r = session.post(
            url,
            data=body,
            headers={
                'Content-Type': body_type,
            }),
    else:
        r = session.get(url, stream=stream)

    _log.debug(f"Response: {r}")
    if stream:
        result = r.iter_content
        _log.debug("Result: <streamed>")
    else:
        result = r.json()
        _log.debug(f"Result: {result}")
    r.raise_for_status()
    return result


def start_compose(workdir, config):
    _log.info("Starting compose")
    request = {
        "blueprint_name": "hatlocker",
        "compose_type": "minimal-raw",
        "branch": "master",
        "size": 0,
    }
    r = call_osbuild_api(config, "/compose", json=request)
    _log.info("Compose started")

    return r['build_id']


def get_compose_results(workdir, config, composeid):
    resultsfile = os.path.join(workdir, 'results.tar')
    if os.path.isfile(resultsfile):
        return resultsfile
    res = call_osbuild_api(
        config,
        f'/compose/results/{composeid}',
        stream=True,
    )
    totalsize = 0
    with open(resultsfile + '.tmp', "wb") as f:
        for chunk in res(chunk_size=4096):
            totalsize += len(chunk)
            f.write(chunk)
    _log.info(f"Retrieved {totalsize / 1024 / 1024}MiB results file")
    os.rename(resultsfile + '.tmp', resultsfile)
    return resultsfile


def extract_compose_results(workdir, resultsfile, composeid):
    imagepath = os.path.join(workdir, 'image.raw')
    if os.path.isfile(imagepath):
        return imagepath
    with open(resultsfile, 'rb') as f:
        with tarfile.TarFile(fileobj=f) as tf:
            _log.debug(f"Results tarball file contents: {tf.getnames()}")
            image = tf.getmember(f"{composeid}-disk.raw.xz")
            _log.debug(f"TarInfo for image: {image}")
            imgf = tf.extractfile(image)
            if imgf is None:
                raise Exception("Image file was not a regular file?")
            with lzma.LZMAFile(imgf) as imgf:
                with open(imagepath + '.tmp', 'wb') as outf:
                    shutil.copyfileobj(imgf, outf)
    os.rename(imagepath + '.tmp', imagepath)
    return imagepath


def prepare_insert_sys_cert(workdir):
    SCRIPTPATH_URL = "https://raw.githubusercontent.com/torvalds/linux/master/scripts/insert-sys-cert.c"
    scriptpath = os.path.join(workdir, 'insert-sys-cert')
    if os.path.isfile(scriptpath):
        return scriptpath
    res = requests.get(SCRIPTPATH_URL)
    res.raise_for_status()
    with open(scriptpath + '.c.tmp', 'wb') as f:
        f.write(res.content)
    os.rename(scriptpath + '.c.tmp', scriptpath + '.c')
    run_command([
        'gcc',
        '-o', scriptpath,
        f'{scriptpath}.c',
    ])
    return scriptpath


def embed_kernel_trusted_key(workdir, keydir):
    scriptpath = prepare_insert_sys_cert(workdir)
    run_command([
        scriptpath,
        '-s', os.path.join(workdir, 'System.map'),
        '-b', os.path.join(workdir, 'vmlinuz'),
        '-c', os.path.join(workdir, 'kernel_trustedkey.pem'),
    ])


def compose(workdir, config, args):
    _log.info('Initializing compose for version %s', args.version)

    composeidfile = os.path.join(workdir, 'composeid')
    if os.path.exists(composeidfile):
        _log.info('Continuing with previous compose')
        with open(composeidfile, 'r') as f:
            composeid = f.read().strip()
    else:
        # Getting definitions
        phase_msg('Get definitions')
        definitions_hash = clone_git_repo(
            config['definitions']['git_url'],
            os.path.join(workdir, 'definitions'))
        _log.info('Definitions hash: %s', definitions_hash)
        phase_msg()

        # Generate blueprint
        phase_msg('Generate blueprint')
        bpcts = get_blueprint(workdir, config, args.version)
        _log.info('Blueprint: %s', bpcts)
        phase_msg()

        # Push blueprint
        phase_msg('Pushing blueprint')
        call_osbuild_api(config, "/blueprints/new", body=bpcts, body_type='text/x-toml')
        phase_msg()

        # Build base image
        phase_msg('Starting compose')
        composeid = start_compose(
            workdir,
            config)
        _log.info('Compose ID: %s', composeid)
        phase_msg()

        with open(composeidfile, 'w') as f:
            f.write(composeid)

    phase_msg('Waiting for base image to finish')
    wait_for_compose(config, composeid)
    phase_msg()

    phase_msg('Getting compose results')
    resultsfile = get_compose_results(workdir, config, composeid)
    phase_msg()

    phase_msg("Extracting compose results")
    imagefile = extract_compose_results(workdir, resultsfile, composeid)
    phase_msg()

    phase_msg('Extracting image contents')
    extract_image(workdir, imagefile)
    phase_msg()

    phase_msg('Creating verity hash volume')
    roothash = create_verity_table(workdir)
    phase_msg()

    phase_msg('Combining volumes')
    combine_files(os.path.join(workdir, 'combinedvol'),
                  os.path.join(workdir, 'rootvol'),
                  os.path.join(workdir, 'hashvol'),
                  gzip=True)
    phase_msg()

    phase_msg('Determining block uuid')
    rootuuid = get_blkfile_uuid(workdir, 'rootvol')
    phase_msg()

    phase_msg('Generating kernel command line')
    create_cmdline(workdir, args.debug_build, config, rootuuid, roothash)
    phase_msg()

    phase_msg('Embedding trusted key into kernel')
    embed_kernel_trusted_key(workdir, config['compose']['keydir'])
    phase_msg()

    raise Exception("TODO")

    phase_msg('Generating EFI binary')
    create_efi_binary(workdir, config)
    phase_msg()

    if not args.skip_test_image:
        phase_msg('Symlinking files')
        assure_symlink(workdir, "efiapp", "%s.efi" % args.version)
        assure_symlink(workdir, "combinedvol", "%s.gz" % args.version)
        phase_msg()

        phase_msg('Getting installer repo')
        installer_hash = clone_git_repo(
            config['testing']['installer_repo'],
            os.path.join(workdir, 'installer'))
        _log.info('Installer hash: %s', installer_hash)
        phase_msg()

        phase_msg('Preparing full disk image for testing')
        _log.debug('Emptying')
        run_command(['truncate', '--size=23G',
                     os.path.join(workdir, 'test.img')])
        run_command(['wipefs', '--force', '--all',
                     os.path.join(workdir, 'test.img')])

        _log.debug('Mounting')
        stdout, stderr = run_command(
            ['losetup', '--show', '--find', os.path.join(workdir, 'test.img')],
                    sudo=True)
        disk = stdout.strip()
        _log.debug('Disk: %s', disk)
        devid = disk[len('/dev/'):]
        _log.debug('Devid: %s', devid)

        _log.debug('Partitioning')
        run_command(["/usr/bin/bash",
                     os.path.join(workdir, "installer",
                                  config['testing']['partition_script']),
                     devid],
                    sudo=True)

        _log.debug('Installing')
        run_command(["/usr/bin/bash",
                     os.path.join(workdir, "installer",
                                  config['testing']['setup_script']),
                     '%sp' % devid,
                     args.version,
                     "file://%s" % workdir,
                     '--skip-efi',
                     '--efi-boot'],
                    sudo=True)

        _log.debug('Unmounting')
        run_command(['losetup', '--detach', disk], sudo=True)
        phase_msg()

    if not args.skip_boot_testing:
        phase_msg('Boot testing')
        cmd = create_qemu_cmd(workdir, config)
        print('QEMU cmd: %s' % cmd)
        print('QEMU cmd: %s' % ' '.join(cmd))
        phase_msg()


def check_keydir(keydir, generate):
    _log.debug(f"Checking keydir {keydir} with generation {generate}")
    if not os.path.exists(keydir):
        raise Exception('Key dir does not exist')

    if not os.path.exists(os.path.join(keydir, 'kernel_trustedkey.pem')):
        if not generate:
            raise Exception("Keydir doesn't contain a kernel trusted key")
        raise Exception("TODO")


def main():
    args = parse_args()
    config = ConfigParser()
    if len(config.read(args.configuration)) != 1:
        print('Invalid configuration file specified')
        sys.exit(1)
    if not args.version:
        if not args.auto_version:
            raise ComposeFailure('No version or auto-version specified')
        args.version = datetime.utcnow().strftime('%Y%m%d%H%M')
    if args.quiet:
        args.verbose = -1
    setup_logging(args.verbose)

    _log.debug('Arguments: %s', args)

    if 'keydir' not in config['compose']:
        raise ComposeFailure('Keydir is required')
    config['compose']['keydir'] = os.path.abspath(config['compose']['keydir'])
    check_keydir(config['compose']['keydir'], args.generate_keys)

    if args.workdir is None:
        args.workdir = tempfile.mkdtemp(prefix='hatlocker-composer-workdir-')

    _log.debug('Workdir: %s', args.workdir)

    compose(args.workdir, config, args)


if __name__ == '__main__':
    main()
